{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados utilizados\n",
    "\n",
    "O conjunto de dados utilizado como base foi o [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) ele é amplamente utilizado para análise e classificação de câncer de mama. Ele contém medições computacionais de características extraídas de imagens de massas celulares em exames de mamografia. As características foram calculadas a partir de imagens digitalizadas de aspirações por agulha fina (FNA), sendo usadas para prever se uma massa é maligna (câncer) ou benigna (não cancerígena). Estes dados foram disponibilizados no repositório [UCI Machine Learning](https://archive.ics.uci.edu/) e originalmente coletados pelo Dr. William H. Wolberg da University of Wisconsin Hospitals, Madison.\n",
    "\n",
    "> Dados anotados **diretamente** por corpo médico regularmente registrado.\n",
    "\n",
    "É preciso ter em mente que modelos de aprendizado de máquina implementados na área de saúde **sempre** devem:\n",
    "\n",
    "- Ter sua acurácia acompanhada por retorno humano (Human Feedback)\n",
    "\n",
    "- Ter explicabilidade (Explainability)\n",
    "\n",
    "- Ter critérios de honestidade definidos (Fairness)\n",
    "\n",
    "- (Para dados de Brasileiros) Obedecer a LGPD para treinamento do modelo e inferência dos dados\n",
    "\n",
    "- (Na União Européia) Obedecer a GPDR para treinamento do modelo e inferência dos dados\n",
    "\n",
    "- (Nos Estados Unidos) Obedecer a HIPAA para treinamento do modelo e inferência dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link para o dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/17/breast+cancer+wisconsin+diagnostic.zip\"\n",
    "\n",
    "# Pasta de destino onde o arquivo será descompactado (na raiz do projeto)\n",
    "dest_folder = \"../data/breast_cancer\"\n",
    "\n",
    "# Arquivo zip de destino\n",
    "dest_zip_file = os.path.join(dest_folder, \"breast_cancer.zip\")\n",
    "\n",
    "# Arquivo parquet de destino\n",
    "dest_parquet_file = os.path.join(dest_folder, \"breast_cancer.parquet\")\n",
    "\n",
    "# Arquivo parquet de destino\n",
    "dest_parquet_laudos_file = os.path.join(dest_folder, \"breast_cancer_laudos.parquet\")\n",
    "\n",
    "if not os.path.exists(dest_folder):\n",
    "\n",
    "    # Crie a pasta se ela não existir\n",
    "    print(f\"Criando a pasta {dest_folder}...\")\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "    # Faça o download e salve o arquivo\n",
    "    print(\"Baixando o dataset...\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Levanta um erro se o download falhar\n",
    "\n",
    "    with open(dest_zip_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Download concluído e salvo em {dest_zip_file}\")\n",
    "\n",
    "    # Descompacte o arquivo\n",
    "    print(\"Descompactando o arquivo...\")\n",
    "    with zipfile.ZipFile(dest_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_folder)\n",
    "\n",
    "    print(f\"Arquivos descompactados em {dest_folder}\")\n",
    "else:\n",
    "    print(f\"Os arquivos já existem em {dest_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para os arquivos de dados e nomes\n",
    "data_file = os.path.join(dest_folder, \"wdbc.data\")\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv(data_file, header=None, sep=\",\")\n",
    "\n",
    "# 12 primeiras colunas\n",
    "data = data.iloc[:, :12]\n",
    "\n",
    "# Definir os nomes das colunas\n",
    "column_names = [\n",
    "    \"id_number\",\n",
    "    \"diagnosis\",\n",
    "    \"radius\",\n",
    "    \"texture\",\n",
    "    \"perimeter\",\n",
    "    \"area\",\n",
    "    \"smoothness\",\n",
    "    \"compactness\",\n",
    "    \"concavity\",\n",
    "    \"concave points\",\n",
    "    \"symmetry\",\n",
    "    \"fractal dimension\"\n",
    "]\n",
    "\n",
    "# Definir os nomes das colunas no DataFrame\n",
    "data.columns = column_names\n",
    "\n",
    "# Adicionar coluna diagnosis_y com valores 0 e 1\n",
    "data['diagnosis_y'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar dataframe em um arquivo parquet na pasta data\n",
    "data.to_parquet(dest_parquet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formato dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatísticas descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição por diagnóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a distribuição dos atributos por diagnóstico\n",
    "sns.pairplot(data, hue='diagnosis', vars=['radius', 'texture', 'perimeter', 'area'], palette='Set2')\n",
    "plt.suptitle(\"Distribuição dos Atributos por Diagnóstico\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação entre features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['radius', 'texture', 'perimeter', 'area', 'smoothness',\n",
    "                'compactness', 'concavity', 'concave points', 'symmetry', 'fractal dimension', 'diagnosis_y']\n",
    "\n",
    "correlation_matrix = data.drop(['id_number', 'diagnosis'], axis=1).corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlação entre Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['radius', 'texture', 'perimeter', 'area', 'smoothness',\n",
    "                'compactness', 'concavity', 'concave points', 'symmetry', 'fractal dimension']\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].hist(data[data['diagnosis'] == 'M'][col], alpha=0.5, label='Maligno', bins=30, color='red')\n",
    "    axes[idx].hist(data[data['diagnosis'] == 'B'][col], alpha=0.5, label='Benigno', bins=30, color='blue')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequência')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_title(f'Distribuição de {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots para identificar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 2, figsize=(15, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    sns.boxplot(data=data, x='diagnosis', y=col, hue='diagnosis', ax=axes[idx], palette='Set2', legend=False)\n",
    "    axes[idx].set_title(f'Boxplot de {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Dados sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar laudos baseado nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker('pt_BR')\n",
    "\n",
    "# Função para traduzir o diagnóstico\n",
    "def traduzir_diagnostico(diagnostico):\n",
    "    return \"Benigno\" if diagnostico == \"B\" else \"Maligno\"\n",
    "\n",
    "# Função para gerar laudo\n",
    "def gerar_laudo(row):\n",
    "    paciente = fake.name()\n",
    "    tamanho = round(row['radius'] * 2, 1)\n",
    "    textura = \"regular\" if row['texture'] < 20 else \"irregular\"\n",
    "    quadrante = random.choice([\"superior esquerdo\", \"superior direito\", \"inferior esquerdo\", \"inferior direito\"])\n",
    "    diagnostico = traduzir_diagnostico(row['diagnosis'])\n",
    "\n",
    "    return f\"\"\"\n",
    "        Paciente: {paciente}\n",
    "        Exame: Mamografia\n",
    "        Data do Exame: {fake.date_this_year()}\n",
    "\n",
    "        Descrição:\n",
    "        Observou-se uma lesão de aproximadamente {tamanho} mm, localizada no quadrante {quadrante}, com bordas {textura}.\n",
    "        O exame sugere que a lesão apresenta características {diagnostico.lower()}.\n",
    "\n",
    "        Conclusão: {diagnostico}.\n",
    "        Recomendação: {('Acompanhar evolução com novo exame em 6 meses' if diagnostico == 'Benigno' else 'Encaminhar para biópsia e avaliação oncológica')}.\n",
    "        \"\"\"\n",
    "\n",
    "# Aplicar em todas as linhas do dataset\n",
    "data['laudo'] = data.apply(gerar_laudo, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar laudos gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre apenas as colunas diagnosis e laudo\n",
    "data[['id_number','diagnosis', 'laudo']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre o texto completo do laudo para os primeiros 3 diagnósticos malignos\n",
    "for laudo in data[data['diagnosis'] == 'M']['laudo'].head(3):\n",
    "    print(laudo)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre o texto completo do laudo para os primeiros 3 diagnósticos benignos\n",
    "for laudo in data[data['diagnosis'] == 'B']['laudo'].head(3):\n",
    "    print(laudo)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionar Ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduzir ruído nos dados\n",
    "def adicionar_ruido(row):\n",
    "\n",
    "    # row['radius'] += random.uniform(-1, 1)  # Pequeno ajuste aleatório no raio\n",
    "    # row['texture'] += random.uniform(-1, 1)  # Pequeno ajuste aleatório na textura\n",
    "\n",
    "    if random.random() < 0.05:  # 5% de chance de alterar o diagnóstico\n",
    "        row['diagnosis'] = \"B\" if row['diagnosis'] == \"M\" else \"M\"\n",
    "\n",
    "    return row\n",
    "\n",
    "data = data.apply(adicionar_ruido, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar dataframe em um arquivo parquet na pasta data\n",
    "data.to_parquet(dest_parquet_laudos_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
